{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7c9cc99",
   "metadata": {},
   "source": [
    "<!-- LTeX: language=fr -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3337ec0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Oracles pour parseurs à transition\n",
    "\n",
    "**Loïc Grobol** [<lgrobol@parisnanterre.fr>](mailto:lgrobol@parisnanterre.fr)\n",
    "\n",
    "2022-01-03\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c7b770",
   "metadata": {},
   "source": [
    "L'objectif est d'écrire des oracles pour des parsers shift-reduce. On va les tester sur des données Universal Dependencies qu'on récupère avec la bibliothèque `datasets`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4871bf",
   "metadata": {},
   "source": [
    "On commence par installer nos dépendances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f41536",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U conllu datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04333864",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\n",
    "   \"universal_dependencies\", \"fr_sequoia\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df533ed7",
   "metadata": {},
   "source": [
    "Voyons ce qu'il a dans le ventre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731af1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41e4a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset[\"train\"]\n",
    "print(train_dataset.info.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f13750",
   "metadata": {},
   "source": [
    "Les données auront cette tête"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811bd128",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57164203",
   "metadata": {},
   "source": [
    "On va d'abord écrire une fonction qui va nous transformer ces données de façon à ne garder que ce qui nous intéresse : identifiants et têtes (et forme pour l'affichage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b032c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "# On pourrait simplement utiliser des tuples\n",
    "# mais c'est plus lisible comme ça\n",
    "@dataclass\n",
    "class Node:\n",
    "    identifier: int\n",
    "    form: str\n",
    "    head: int\n",
    "\n",
    "\n",
    "def buffer_from_dict(d):\n",
    "    # On gère les multiword tokens qu'on repère parce que\n",
    "    # leur tête est `\"None\"`, oui, oui, la chaine de caractères,\n",
    "    # par l'objet `None`\n",
    "    words_with_heads = [\n",
    "        (w, int(h))\n",
    "        for w, h in zip(d[\"tokens\"], d[\"head\"])\n",
    "        if h != \"None\"\n",
    "    ]\n",
    "    return [\n",
    "        Node(\n",
    "            identifier=i,\n",
    "            form=w,\n",
    "            head=h,\n",
    "        )\n",
    "        \n",
    "        for i, (w, h) in enumerate([(\"ROOT\", 0), *words_with_heads])\n",
    "    ]\n",
    "\n",
    "buffer_from_dict(train_dataset[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf44ee57",
   "metadata": {},
   "source": [
    "Un oracle pour le système de transition *arc-standard* ([Nivre, 2004](https://aclanthology.org/W04-0308))) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df9b5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Iterable\n",
    "from collections import Counter\n",
    "\n",
    "def arc_standard_oracle(buffer: List[Node]) -> Iterable[str]:\n",
    "    # On copie le buffer pour ne pas le détruire et on le retourne pour\n",
    "    # pouvoir   `pop`er optimalement\n",
    "    # On pourrait aussi écrire `list(reversed(buffer))`\n",
    "    buffer = buffer[::-1]\n",
    "    # Comme d'habitude, une liste c'est une pile, on commence avec la racine\n",
    "    # dessus\n",
    "    stack = [buffer.pop()]\n",
    "    # Pour ne pas réduire un nœud avant d'avoir trouvé tous ses dépendants,\n",
    "    # on les compte (On pourrait utiliser un générateur\n",
    "    # plutôt qu'une boucle)\n",
    "    remaining_dependents = Counter()\n",
    "    for node in buffer:\n",
    "        remaining_dependents[node.head] += 1\n",
    "\n",
    "    while buffer or stack:\n",
    "        print([t.form for t in stack], [t.form for t in reversed(buffer)], sep=\"\\t\")\n",
    "        if len(stack) < 2:\n",
    "            if buffer:\n",
    "                yield \"SHIFT\"\n",
    "                stack.append(buffer.pop())\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "        stack_top = stack[-1]\n",
    "        stack_under = stack[-2]\n",
    "        if stack_top.head == stack_under.identifier and not remaining_dependents[stack_top.identifier]:\n",
    "            yield \"REDUCE-RIGHT\"\n",
    "            remaining_dependents[stack_under.identifier] -= 1\n",
    "            stack.pop()\n",
    "        elif stack_top.identifier == stack_under.head and not remaining_dependents[stack_under.identifier]:\n",
    "            yield \"REDUCE-LEFT\"\n",
    "            remaining_dependents[stack_top.identifier] -= 1\n",
    "            stack.pop(-2)\n",
    "        else:\n",
    "            if buffer:\n",
    "                yield \"SHIFT\"\n",
    "                stack.append(buffer.pop())\n",
    "            else:\n",
    "                raise ValueError(\"Non-projective tree\")\n",
    "\n",
    "list(arc_standard_oracle(buffer_from_dict(train_dataset[5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b572f569",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arc_eager_oracle(buffer: List[Node]) -> List[str]:\n",
    "    buffer = buffer[::-1]\n",
    "    stack = [buffer.pop()]\n",
    "    \n",
    "    # On pourrait aussi le faire quand on pousse sur la stack\n",
    "    has_left_dependents = set()\n",
    "    for node in buffer[:-1]:\n",
    "        if node.identifier < node.head:\n",
    "            has_left_dependents.add(node.head)\n",
    "            \n",
    "    # Nécessaire uniquement si on a pas de garantie que l'arbre soit\n",
    "    # projectif\n",
    "    has_head = {node.identifier: False for node in buffer[:-1]}\n",
    "\n",
    "    while buffer:\n",
    "        print([t.form for t in stack], [t.form for t in reversed(buffer)], sep=\"\\t\")\n",
    "        stack_top = stack[-1]\n",
    "        buffer_top = buffer[-1]\n",
    "        if stack_top.head == buffer_top.identifier:\n",
    "            # Superflu mais agréable\n",
    "            has_head[stack_top.identifier] = True\n",
    "            yield \"LEFT-ARC\"\n",
    "            stack.pop()\n",
    "        elif stack_top.identifier == buffer_top.head:\n",
    "            yield \"RIGHT-ARC\"\n",
    "            has_head[buffer_top.identifier] = True\n",
    "            stack.append(buffer.pop())\n",
    "        # Trick galaxy brain de la projectivité: si on a `… A B …`\n",
    "        # avec un arc qui part de ou qui arrive à B et dont l'autre\n",
    "        # extrémité est à gauche de A, alors A nepeut pas avoir d'arc\n",
    "        # qui le relie à un truc à droite.\n",
    "        # Donc la tête de A est à sa gauche (ce n'est pas B sinon\n",
    "        # on aurait left-arc), donc on l'a déjà trouvée (et c'est même\n",
    "        # le nœud juste en dessous).\n",
    "        elif buffer_top.identifier in has_left_dependents:\n",
    "            if not has_head[stack_top.identifier]:\n",
    "                raise ValueError(\"Non-projective tree\")\n",
    "            yield \"REDUCE\"\n",
    "            stack.pop()\n",
    "        else:\n",
    "            yield \"SHIFT\"\n",
    "            stack.append(buffer.pop())\n",
    "    while len(stack) > 1:\n",
    "        print([t.form for t in stack], [t.form for t in reversed(buffer)], sep=\"\\t\")\n",
    "        # On pourrait pop ici mais c'est sale\n",
    "        if not has_head[stack[-1].identifier]:\n",
    "            raise ValueError(\"Non-projective tree\")\n",
    "        yield \"REDUCE\"\n",
    "        stack.pop()\n",
    "\n",
    "list(arc_eager_oracle(buffer_from_dict(train_dataset[5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3165ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(arc_eager_oracle(buffer_from_dict(train_dataset[6])))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md",
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
